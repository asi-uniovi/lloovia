# vim: syntax=python tabstop=4 expandtab
# coding: utf-8

USE_PAPER_DATASET = True

include: "Snakefile.definitions"
import os,sys,inspect
currentdir = os.path.dirname(
    os.path.abspath(inspect.getfile(inspect.currentframe()))
        )
sys.path.insert(0, os.path.join(currentdir, "src/solve"))
sys.path.insert(0, os.path.join(currentdir, "src/visualization"))
sys.path.insert(0, os.path.join(currentdir, "src/data"))

include: "Snakefile.rules"

interim_folder = "/tmp/interim"
#interim_folder = "data/interim"

# PHASE I DESIRED RESULTS
# One file per scenario, level and each max_bins value
wikipedia_phase_I = expand("%s/phaseI/case_wikipedia_2014_bins_{bins}.pickle" % 
                           interim_folder, bins=BINS)

# Append also one file for the case max_bins=None
wikipedia_phase_I.extend(expand("%s/phaseI/case_wikipedia_{year}_nobins.pickle" % interim_folder,
                        year=[2014]))

# wikipedia_phase_I.extend(expand("%s/phaseI/case_wikipedia_{year}_bins_40.pickle" % interim_folder,
#                        year=[2013, 2014, 2015]))

# PHASE II DESIRED RESULTS
# For the Perfect Prediction, one solution per scenario, level and max_bins
wikipedia_phase_II_PP = expand("%s/phaseII_PP/case_wikipedia_2014_bins_{bins}.pickle" % 
                                interim_folder, bins=BINS)

wikipedia_phase_II_R = expand("%s/phaseII_R/case_wikipedia_{year}_bins_40.pickle" %
                                interim_folder, year=[2013, 2014])
wikipedia_phase_II_O = expand("%s/phaseII/case_wikipedia_{year}_oracle.pickle" %
                           interim_folder, year=[2013, 2014])
wikipedia_phase_II_OD = expand("%s/phaseII_OD/case_wikipedia_{year}_bins_40.pickle" %
                                interim_folder, year=[2013,2014])
wikipedia_phase_I_multi = expand("%s/phaseI/case_wikipedia_{year}_multi_{provider}_bins_40.pickle" %
                                interim_folder, year=2014, provider=["Amazon", "Azure", "Both"])
wikipedia_phase_II_multi = expand("%s/phaseII_PP/case_wikipedia_{year}_multi_{provider}_bins_40.pickle" %
                                interim_folder, year=2014, provider=["Amazon", "Azure", "Both"])


            

# # For the non perfect prediction, one solution per scenario, level and max_bins
# phase_II_realization = expand("%s/phaseII_R/case_{case}_level_{level}_bins_{bins}.pickle" %
#                               interim_folder, case=CASES, level=LEVELS, bins=[20])
# # NOTE: Only for max_bins=20 to reproduce the results in the paper.
# # Replace with bins=BINS to get results for all max_bins values
# 
# # For the oracle, one solution per scenario and level (it uses max_bins=None)
# phase_II_oracle = expand("%s/phaseII/case_{case}_level_{level}_oracle.pickle" %
#                         interim_folder, case=CASES, level=LEVELS)

# Cloud infrastructure
instances_for_wikipedia_binning_experiments = "%s/instances_for_wikpedia_binning_experiments.pickle" % interim_folder


rule all:
    input: wikipedia_phase_I, wikipedia_phase_II_PP, wikipedia_phase_II_R, 
           wikipedia_phase_II_O, wikipedia_phase_II_OD,
           wikipedia_phase_I_multi, wikipedia_phase_II_multi

rule run_phase_I:
    input: wikipedia_phase_I

rule run_phase_II_PP:
    input: wikipedia_phase_II_PP

rule run_phase_II_R:
    input: wikipedia_phase_II_R

rule run_phase_II_O:
    input: wikipedia_phase_II_O

rule run_phase_II_OD:
    input: wikipedia_phase_II_OD


rule create_instances_for_wikipedia_binning_experiments:
    input:  "data/processed/benchmarks_wikibench.csv", "data/processed/providers_amazon_data.csv"
    output: instances_for_wikipedia_binning_experiments
    message: "Creating instances for wikipedia binning experiments"
    run:
       import create_wikipedia_infrastructure as wikipedia
       wikipedia.create_instances_binning_analysis(input[0], input[1], output[0])

rule create_instances_for_wikipedia_multicloud_azure:
    input: "data/processed/benchmarks_oldisim.csv", "data/processed/providers_{provider}_data.csv"
    output: "%s/instances_for_wikipedia_multicloud_{provider}.pickle" % interim_folder
    message: "Creating {wildcards.provider} cloud infrastructure for Wikipedia multiregion analysis"
    run:
        import create_wikipedia_infrastructure as wikipedia
        wikipedia.create_instances_multicloud_analysis(
                benchmark_data=input[0], 
                provider_data=input[1], 
                provider=wildcards.provider,
                output_file=output[0])

rule solve_wikipedia_Phase_I_with_bins:
    input: instances_for_wikipedia_binning_experiments, "data/processed/traces_en_wikipedia.csv"
    output: "%s/phaseI/case_wikipedia_{year,\d+}_bins_{bins}.pickle" % interim_folder  
    message: "Solving Phase I for wikipedia {wildcards.year}, with {wildcards.bins} bins"
    run:
       import wikipedia_experiments
       wikipedia_experiments.perform_experiment_phase_I(
            infrastructure_file=input[0], workload_file=input[1],
            year=wildcards.year,
            max_bins=int(wildcards.bins),
            frac_gap=0.001,
            max_seconds=1*60*60,
            output_file=output[0]
            )

rule solve_wikipedia_Phase_I_without_bins:
    input: instances_for_wikipedia_binning_experiments, "data/processed/traces_en_wikipedia.csv"
    output: "%s/phaseI/case_wikipedia_{year}_nobins.pickle" % interim_folder  
    message: "Solving Phase I for wikipedia {wildcards.year}, without binning"
    run:
       import wikipedia_experiments
       wikipedia_experiments.perform_experiment_phase_I(
            infrastructure_file=input[0], workload_file=input[1],
            year=wildcards.year,
            max_bins=None,
            frac_gap=None,
            max_seconds=1*60*60,
            output_file=output[0]
            )
    
rule solve_wikipedia_phase_II_PP:
    # The "Perfect Prediction" case assumes that Phase I had the exact workload
    # So we use the same LTWP used in Phase I, for Phase II
    input: instances_for_wikipedia_binning_experiments, "data/processed/traces_en_wikipedia.csv",
           "%s/phaseI/case_wikipedia_2014_bins_{bins}.pickle" % interim_folder
    output: "%s/phaseII_PP/case_wikipedia_2014_bins_{bins}.pickle" % interim_folder
    message: "Solving Phase II, perfect prediction, for wikipedia 2014, {wildcards.bins} bins"
    run:
        import wikipedia_experiments
        wikipedia_experiments.perform_experiment_phase_II(
            infrastructure_file=input[0], 
            workload_file=input[1], 
            year=2014,
            phase_I_solution=input[2],
            output_file=output[0],
            )

def solution_for_previous_year(w):
    return ("%s/phaseI/case_wikipedia_%s_bins_%s.pickle" % 
            (interim_folder, int(w.year)-1, w.bins))

rule solve_wikipedia_phase_II_R:
    input: instances_for_wikipedia_binning_experiments,
            "data/processed/traces_en_wikipedia.csv",
            solution_for_previous_year, 
    output: "%s/phaseII_R/case_wikipedia_{year}_bins_{bins}.pickle" % interim_folder
    message: "Solving wikipedia Phase II for {wildcards.year}, {wildcards.bins} bins using phase I with previous year as prediction"
    run:
        import wikipedia_experiments
        print(list(input), list(output), list(wildcards))
        wikipedia_experiments.perform_experiment_phase_II(
            infrastructure_file=input[0], 
            workload_file=input[1], 
            year=wildcards.year,
            phase_I_solution=input[2],
            output_file=output[0],
            )

rule solve_wikipedia_phase_II_O:
    input: instances_for_wikipedia_binning_experiments, "data/processed/traces_en_wikipedia.csv"
    output: "%s/phaseII/case_wikipedia_{year}_oracle.pickle" % interim_folder  
    message: "Solving oracle for wikipedia {wildcards.year}, without binning"
    run:
       import wikipedia_experiments
       wikipedia_experiments.perform_experiment_phase_I(
            infrastructure_file=input[0], workload_file=input[1],
            year=wildcards.year,
            max_bins=None,
            frac_gap=None,
            max_seconds=1*60*60,
            output_file=output[0]
            )

rule solve_wikipedia_phase_II_OD:
    input: instances_for_wikipedia_binning_experiments, "data/processed/traces_en_wikipedia.csv"
    output: "%s/phaseII_OD/case_wikipedia_{year}_bins_40.pickle" % interim_folder  
    message: "Solving Phase II for wikipedia {wildcards.year}, only on-demand instances"
    run:
       import wikipedia_experiments
       wikipedia_experiments.perform_experiment_phase_II_od_only(
            infrastructure_file=input[0], workload_file=input[1],
            year=wildcards.year,
            frac_gap=None,
            max_seconds=1*60*60,
            output_file=output[0]
            )

rule solve_wikipedia_phase_I_multi:
    input:  "%s/instances_for_wikipedia_multicloud_azure.pickle" % interim_folder,
            "%s/instances_for_wikipedia_multicloud_amazon.pickle" % interim_folder,
            "data/processed/traces_en_wikipedia.csv"
    output: "%s/phaseI/case_wikipedia_{year}_multi_{provider}_bins_40.pickle" % interim_folder
    message: "Solving phase I for wikipedia {wildcards.year}, multicloud case, provider {wildcards.provider}"
    run:
        import wikipedia_experiments
        wikipedia_experiments.perform_experiment_multiregion_phase_I(
            azure_infrastructure_file=input[0],
            amazon_infrastructure_file=input[1],
            workload_file=input[2],
            year=wildcards.year,
            max_bins=40,
            providers_to_use=wildcards.provider,
            output_file=output[0] 
            )

rule solve_wikipedia_phase_II_multi:
    input:  "%s/instances_for_wikipedia_multicloud_azure.pickle" % interim_folder,
            "%s/instances_for_wikipedia_multicloud_amazon.pickle" % interim_folder,
            "data/processed/traces_en_wikipedia.csv", 
            "%s/phaseI/case_wikipedia_{year}_multi_{provider}_bins_40.pickle" % interim_folder
    output: "%s/phaseII_PP/case_wikipedia_{year}_multi_{provider}_bins_40.pickle" % interim_folder
    message: "Solving phase II for wikipedia {wildcards.year}, multicloud case, provider {wildcards.provider}"
    run:
        import wikipedia_experiments
        wikipedia_experiments.perform_experiment_multiregion_phase_II(
            azure_infrastructure_file=input[0],
            amazon_infrastructure_file=input[1],
            workload_file=input[2],
            year=wildcards.year,
            providers_to_use=wildcards.provider,
            phase_I_solution=input[3],
            output_file=output[0] 
            )

#
#
# rule solve_case_phase_II_realization:
#     # The imperfect prediction uses a STWP different from LTWP
#     input: instances_for_synthetic_experiments, "data/processed/traces_synthetic_{case}_STWP.csv",
#            "%s/phaseI/case_{case}_level_{level}_bins_{bins}.pickle" % interim_folder
#     output: "%s/phaseII_R/case_{case}_level_{level}_bins_{bins}.pickle" % interim_folder
#     message: "Solving Phase II, imperfect prediction, for '{wildcards.case}-{wildcards.level}'"
#     run:
#         import experiments
#         experiments.perform_experiment_phase_II(
#             infrastructure_file=input[0], 
#             workload_file=input[1], 
#             level=int(wildcards.level),
#             phase_I_solution=input[2],
#             output_file=output[0],
#             )
# 
# rule solve_case_phase_II_oracle:
#     # Oracle knowns the future STWP, so we build a problem which uses it as prediction
#     # and solve Phase I for it
#     input: instances_for_synthetic_experiments, "data/processed/traces_synthetic_{case}_STWP.csv"
#     output: "%s/phaseII/case_{case}_level_{level}_oracle.pickle" % interim_folder  
#     message: "Solving Phase II, realization oracle, for '{wildcards.case}-{wildcards.level}'"
#     run:
#        import experiments
#        experiments.perform_experiment_phase_I(
#             infrastructure_file=input[0], workload_file=input[1],
#             level=int(wildcards.level),
#             max_bins=None,
#             output_file=output[0],
#             frac_gap=None,
#             max_seconds=60*60
#             )
